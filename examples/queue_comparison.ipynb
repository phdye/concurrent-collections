{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrent Queue Comparison\n",
    "\n",
    "Compare the three queue implementations:\n",
    "- **SCQ** (Scalable Circular Queue) - Portable, single-width CAS\n",
    "- **LCRQ** (Linked Concurrent Ring Queue) - x86-64 only, fastest\n",
    "- **WCQ** (Wait-Free Circular Queue) - Bounded latency guarantee\n",
    "\n",
    "This notebook helps you choose the right queue for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import threading\n",
    "import platform\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Callable, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Detect platform\n",
    "IS_X86_64 = platform.machine() in ('x86_64', 'AMD64')\n",
    "print(f\"Platform: {platform.machine()}\")\n",
    "print(f\"LCRQ available: {IS_X86_64}\")\n",
    "\n",
    "# Try to import real library\n",
    "try:\n",
    "    from concurrent_collections import LockFreeQueue, FastQueue, WaitFreeQueue\n",
    "    SIMULATION_MODE = False\n",
    "    print(\"Using concurrent_collections library\")\n",
    "except ImportError:\n",
    "    SIMULATION_MODE = True\n",
    "    print(\"Library not installed - running in simulation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation classes\n",
    "if SIMULATION_MODE:\n",
    "    import queue\n",
    "    \n",
    "    class SimulatedQueue:\n",
    "        def __init__(self, name, capacity=1024):\n",
    "            self.name = name\n",
    "            self._queue = queue.Queue(maxsize=capacity)\n",
    "            self._capacity = capacity\n",
    "        \n",
    "        def put(self, item):\n",
    "            try:\n",
    "                self._queue.put_nowait(item)\n",
    "                return True\n",
    "            except queue.Full:\n",
    "                return False\n",
    "        \n",
    "        def get(self):\n",
    "            try:\n",
    "                return self._queue.get_nowait()\n",
    "            except queue.Empty:\n",
    "                return None\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self._queue.qsize()\n",
    "    \n",
    "    LockFreeQueue = lambda cap=1024: SimulatedQueue(\"SCQ\", cap)\n",
    "    FastQueue = lambda cap=1024: SimulatedQueue(\"LCRQ\" if IS_X86_64 else \"SCQ\", cap)\n",
    "    WaitFreeQueue = lambda cap=1024, threads=8: SimulatedQueue(\"WCQ\", cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QueueBenchmarkResult:\n",
    "    name: str\n",
    "    producers: int\n",
    "    consumers: int\n",
    "    ops_per_sec: float\n",
    "    enqueue_p50_us: float\n",
    "    enqueue_p99_us: float\n",
    "    enqueue_max_us: float  # Important for wait-free verification\n",
    "    dequeue_p50_us: float\n",
    "    dequeue_p99_us: float\n",
    "    dequeue_max_us: float\n",
    "    failed_enqueues: int\n",
    "    failed_dequeues: int\n",
    "\n",
    "def benchmark_queue(queue_factory: Callable, name: str,\n",
    "                    producers: int, consumers: int,\n",
    "                    ops_per_thread: int = 5000) -> QueueBenchmarkResult:\n",
    "    \"\"\"Benchmark a queue with producer/consumer pattern.\"\"\"\n",
    "    q = queue_factory()\n",
    "    \n",
    "    enqueue_latencies = []\n",
    "    dequeue_latencies = []\n",
    "    failed_enq = [0]\n",
    "    failed_deq = [0]\n",
    "    lock = threading.Lock()\n",
    "    done = threading.Event()\n",
    "    \n",
    "    def producer():\n",
    "        local_lat = []\n",
    "        failures = 0\n",
    "        for i in range(ops_per_thread):\n",
    "            start = time.perf_counter_ns()\n",
    "            success = q.put(i)\n",
    "            elapsed = (time.perf_counter_ns() - start) / 1000\n",
    "            local_lat.append(elapsed)\n",
    "            if not success:\n",
    "                failures += 1\n",
    "        with lock:\n",
    "            enqueue_latencies.extend(local_lat)\n",
    "            failed_enq[0] += failures\n",
    "    \n",
    "    def consumer():\n",
    "        local_lat = []\n",
    "        failures = 0\n",
    "        count = 0\n",
    "        target = (producers * ops_per_thread) // consumers\n",
    "        while count < target and not done.is_set():\n",
    "            start = time.perf_counter_ns()\n",
    "            item = q.get()\n",
    "            elapsed = (time.perf_counter_ns() - start) / 1000\n",
    "            local_lat.append(elapsed)\n",
    "            if item is None:\n",
    "                failures += 1\n",
    "                time.sleep(0.0001)  # Brief sleep on empty\n",
    "            else:\n",
    "                count += 1\n",
    "        with lock:\n",
    "            dequeue_latencies.extend(local_lat)\n",
    "            failed_deq[0] += failures\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=producers + consumers) as executor:\n",
    "        prod_futures = [executor.submit(producer) for _ in range(producers)]\n",
    "        cons_futures = [executor.submit(consumer) for _ in range(consumers)]\n",
    "        \n",
    "        for f in prod_futures:\n",
    "            f.result()\n",
    "        done.set()\n",
    "        for f in cons_futures:\n",
    "            f.result(timeout=5)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    total_ops = producers * ops_per_thread * 2  # enqueue + dequeue\n",
    "    \n",
    "    def percentile(data, p):\n",
    "        if not data:\n",
    "            return 0\n",
    "        sorted_data = sorted(data)\n",
    "        idx = min(int(len(sorted_data) * p), len(sorted_data) - 1)\n",
    "        return sorted_data[idx]\n",
    "    \n",
    "    return QueueBenchmarkResult(\n",
    "        name=name,\n",
    "        producers=producers,\n",
    "        consumers=consumers,\n",
    "        ops_per_sec=total_ops / duration,\n",
    "        enqueue_p50_us=percentile(enqueue_latencies, 0.50),\n",
    "        enqueue_p99_us=percentile(enqueue_latencies, 0.99),\n",
    "        enqueue_max_us=max(enqueue_latencies) if enqueue_latencies else 0,\n",
    "        dequeue_p50_us=percentile(dequeue_latencies, 0.50),\n",
    "        dequeue_p99_us=percentile(dequeue_latencies, 0.99),\n",
    "        dequeue_max_us=max(dequeue_latencies) if dequeue_latencies else 0,\n",
    "        failed_enqueues=failed_enq[0],\n",
    "        failed_dequeues=failed_deq[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks for different configurations\n",
    "configs = [(1, 1), (2, 2), (4, 4), (8, 8)]\n",
    "\n",
    "scq_results = []\n",
    "lcrq_results = [] if IS_X86_64 else None\n",
    "wcq_results = []\n",
    "\n",
    "print(\"Running throughput benchmarks...\")\n",
    "for prod, cons in configs:\n",
    "    print(f\"  {prod}P/{cons}C...\")\n",
    "    scq_results.append(benchmark_queue(\n",
    "        lambda: LockFreeQueue(1024), \"SCQ\", prod, cons))\n",
    "    if IS_X86_64:\n",
    "        lcrq_results.append(benchmark_queue(\n",
    "            lambda: FastQueue(1024), \"LCRQ\", prod, cons))\n",
    "    wcq_results.append(benchmark_queue(\n",
    "        lambda: WaitFreeQueue(1024, prod + cons), \"WCQ\", prod, cons))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Throughput comparison\n",
    "ax1 = axes[0]\n",
    "x_labels = [f\"{p}P/{c}C\" for p, c in configs]\n",
    "x = np.arange(len(configs))\n",
    "width = 0.25\n",
    "\n",
    "scq_tp = [r.ops_per_sec / 1000 for r in scq_results]\n",
    "wcq_tp = [r.ops_per_sec / 1000 for r in wcq_results]\n",
    "\n",
    "bars = [ax1.bar(x - width, scq_tp, width, label='SCQ', color='steelblue')]\n",
    "if IS_X86_64 and lcrq_results:\n",
    "    lcrq_tp = [r.ops_per_sec / 1000 for r in lcrq_results]\n",
    "    bars.append(ax1.bar(x, lcrq_tp, width, label='LCRQ', color='coral'))\n",
    "bars.append(ax1.bar(x + width, wcq_tp, width, label='WCQ', color='forestgreen'))\n",
    "\n",
    "ax1.set_xlabel('Configuration')\n",
    "ax1.set_ylabel('Throughput (K ops/sec)')\n",
    "ax1.set_title('Queue Throughput Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(x_labels)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Max latency (critical for wait-free)\n",
    "ax2 = axes[1]\n",
    "scq_max = [r.enqueue_max_us for r in scq_results]\n",
    "wcq_max = [r.enqueue_max_us for r in wcq_results]\n",
    "\n",
    "ax2.plot(x_labels, scq_max, 'o-', label='SCQ', color='steelblue')\n",
    "if IS_X86_64 and lcrq_results:\n",
    "    lcrq_max = [r.enqueue_max_us for r in lcrq_results]\n",
    "    ax2.plot(x_labels, lcrq_max, 's-', label='LCRQ', color='coral')\n",
    "ax2.plot(x_labels, wcq_max, '^-', label='WCQ', color='forestgreen')\n",
    "\n",
    "ax2.set_xlabel('Configuration')\n",
    "ax2.set_ylabel('Max Latency (μs)')\n",
    "ax2.set_title('Worst-Case Latency (Wait-Free Verification)')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare latency at 4P/4C configuration\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "idx = 2  # 4P/4C\n",
    "percentiles = ['P50', 'P99', 'Max']\n",
    "x = np.arange(len(percentiles))\n",
    "width = 0.25\n",
    "\n",
    "scq_lat = [scq_results[idx].enqueue_p50_us,\n",
    "           scq_results[idx].enqueue_p99_us,\n",
    "           scq_results[idx].enqueue_max_us]\n",
    "wcq_lat = [wcq_results[idx].enqueue_p50_us,\n",
    "           wcq_results[idx].enqueue_p99_us,\n",
    "           wcq_results[idx].enqueue_max_us]\n",
    "\n",
    "ax.bar(x - width/2, scq_lat, width, label='SCQ', color='steelblue')\n",
    "if IS_X86_64 and lcrq_results:\n",
    "    lcrq_lat = [lcrq_results[idx].enqueue_p50_us,\n",
    "                lcrq_results[idx].enqueue_p99_us,\n",
    "                lcrq_results[idx].enqueue_max_us]\n",
    "    ax.bar(x, lcrq_lat, width, label='LCRQ', color='coral')\n",
    "ax.bar(x + width/2, wcq_lat, width, label='WCQ', color='forestgreen')\n",
    "\n",
    "ax.set_xlabel('Percentile')\n",
    "ax.set_ylabel('Latency (μs)')\n",
    "ax.set_title('Enqueue Latency Distribution (4P/4C)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(percentiles)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_queue(results_8p8c: dict):\n",
    "    \"\"\"Generate queue recommendation based on benchmark results.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"QUEUE SELECTION GUIDE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n1. FOR MAXIMUM THROUGHPUT:\")\n",
    "    if IS_X86_64:\n",
    "        print(\"   -> FastQueue (LCRQ on x86-64)\")\n",
    "        print(\"   Uses double-width CAS for best performance\")\n",
    "    else:\n",
    "        print(\"   -> LockFreeQueue (SCQ)\")\n",
    "        print(\"   Best portable option\")\n",
    "    \n",
    "    print(\"\\n2. FOR PORTABILITY:\")\n",
    "    print(\"   -> LockFreeQueue (SCQ)\")\n",
    "    print(\"   Works on all platforms with single-width CAS\")\n",
    "    \n",
    "    print(\"\\n3. FOR BOUNDED LATENCY / REAL-TIME:\")\n",
    "    print(\"   -> WaitFreeQueue (WCQ)\")\n",
    "    print(\"   Guarantees O(n) completion regardless of contention\")\n",
    "    \n",
    "    print(\"\\n4. AUTOMATIC SELECTION:\")\n",
    "    print(\"   -> FastQueue (auto-selects best backend)\")\n",
    "    print(f\"   On this machine: {'LCRQ' if IS_X86_64 else 'SCQ'}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARK RESULTS (8P/8C configuration)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    scq = scq_results[-1]\n",
    "    wcq = wcq_results[-1]\n",
    "    \n",
    "    print(f\"\\n{'Queue':<12} {'Throughput':>15} {'P99 Latency':>15} {'Max Latency':>15}\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'SCQ':<12} {scq.ops_per_sec/1000:>12.1f} K/s {scq.enqueue_p99_us:>12.1f} μs {scq.enqueue_max_us:>12.1f} μs\")\n",
    "    if IS_X86_64 and lcrq_results:\n",
    "        lcrq = lcrq_results[-1]\n",
    "        print(f\"{'LCRQ':<12} {lcrq.ops_per_sec/1000:>12.1f} K/s {lcrq.enqueue_p99_us:>12.1f} μs {lcrq.enqueue_max_us:>12.1f} μs\")\n",
    "    print(f\"{'WCQ':<12} {wcq.ops_per_sec/1000:>12.1f} K/s {wcq.enqueue_p99_us:>12.1f} μs {wcq.enqueue_max_us:>12.1f} μs\")\n",
    "\n",
    "recommend_queue(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade-off Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║                    QUEUE TRADE-OFF SUMMARY                       ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║ Queue │ Progress    │ Throughput │ Latency Bound │ Portability  ║\n",
    "╠═══════╪═════════════╪════════════╪═══════════════╪══════════════╣\n",
    "║ SCQ   │ Lock-free   │ Good       │ Unbounded     │ All platforms║\n",
    "║ LCRQ  │ Lock-free   │ Excellent  │ Unbounded     │ x86-64 only  ║\n",
    "║ WCQ   │ Wait-free   │ Moderate   │ O(n) bounded  │ All platforms║\n",
    "╚═══════╧═════════════╧════════════╧═══════════════╧══════════════╝\n",
    "\n",
    "Key:\n",
    "- Lock-free: At least one thread makes progress\n",
    "- Wait-free: Every thread makes progress in bounded steps\n",
    "- O(n): Proportional to thread count\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
