{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memory Performance Analysis\n",
        "\n",
        "Interactive analysis of memory allocation patterns using `MemoryProfiler`.\n",
        "\n",
        "This notebook helps you:\n",
        "- Profile allocation patterns in your workloads\n",
        "- Identify memory hotspots and fragmentation\n",
        "- Detect memory leaks\n",
        "- Analyze cross-thread memory operations\n",
        "- Generate optimization recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "\n",
        "# Check if concurrent_collections is available\n",
        "try:\n",
        "    from concurrent_collections import MemoryProfiler, SkipListMap, config\n",
        "    LIBRARY_AVAILABLE = True\n",
        "    print(f\"concurrent_collections loaded successfully\")\n",
        "    print(f\"Python: {sys.version}\")\n",
        "    print(f\"Free-threaded: {not sys._is_gil_enabled() if hasattr(sys, '_is_gil_enabled') else 'N/A'}\")\n",
        "except ImportError:\n",
        "    LIBRARY_AVAILABLE = False\n",
        "    print(\"concurrent_collections not installed - running in simulation mode\")\n",
        "    print(\"Install with: pip install concurrent_collections\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Simulation Mode (when library not installed)\n",
        "\n",
        "If the library isn't installed, we provide simulated data for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LIBRARY_AVAILABLE:\n",
        "    @dataclass\n",
        "    class SizeHistogram:\n",
        "        buckets: dict\n",
        "        total_count: int\n",
        "        total_bytes: int\n",
        "        \n",
        "        def hot_sizes(self, top_n=5):\n",
        "            sorted_buckets = sorted(self.buckets.items(), key=lambda x: -x[1])\n",
        "            return sorted_buckets[:top_n]\n",
        "    \n",
        "    @dataclass\n",
        "    class ThreadMemoryStats:\n",
        "        thread_id: int\n",
        "        thread_name: Optional[str]\n",
        "        alloc_count: int\n",
        "        free_count: int\n",
        "        alloc_bytes: int\n",
        "        free_bytes: int\n",
        "        cross_thread_frees_sent: int\n",
        "        cross_thread_frees_received: int\n",
        "    \n",
        "    @dataclass\n",
        "    class FragmentationMetrics:\n",
        "        internal_fragmentation: float\n",
        "        external_fragmentation: float\n",
        "        largest_free_block: int\n",
        "        free_block_count: int\n",
        "        utilization: float\n",
        "    \n",
        "    @dataclass\n",
        "    class MemoryProfilerReport:\n",
        "        alloc_count: int\n",
        "        free_count: int\n",
        "        alloc_bytes: int\n",
        "        free_bytes: int\n",
        "        current_allocated: int\n",
        "        peak_allocated: int\n",
        "        alloc_rate: float\n",
        "        free_rate: float\n",
        "        bytes_rate: float\n",
        "        alloc_latency_p50: float\n",
        "        alloc_latency_p95: float\n",
        "        alloc_latency_p99: float\n",
        "        alloc_latency_p999: float\n",
        "        free_latency_p50: float\n",
        "        free_latency_p95: float\n",
        "        free_latency_p99: float\n",
        "        free_latency_p999: float\n",
        "        cross_thread_free_count: int\n",
        "        cross_thread_free_pct: float\n",
        "        size_histogram: SizeHistogram\n",
        "        thread_stats: list\n",
        "        fragmentation: FragmentationMetrics\n",
        "        leaked_allocations: Optional[list]\n",
        "        leaked_bytes: int\n",
        "        duration_seconds: float\n",
        "        start_time: datetime\n",
        "        end_time: datetime\n",
        "    \n",
        "    def generate_simulated_report():\n",
        "        \"\"\"Generate realistic simulated profiler data.\"\"\"\n",
        "        return MemoryProfilerReport(\n",
        "            alloc_count=1_523_456,\n",
        "            free_count=1_523_400,\n",
        "            alloc_bytes=98_765_432,\n",
        "            free_bytes=98_760_000,\n",
        "            current_allocated=5_432,\n",
        "            peak_allocated=15_234_567,\n",
        "            alloc_rate=152345.6,\n",
        "            free_rate=152340.0,\n",
        "            bytes_rate=9876543.2,\n",
        "            alloc_latency_p50=15.2,\n",
        "            alloc_latency_p95=42.8,\n",
        "            alloc_latency_p99=128.5,\n",
        "            alloc_latency_p999=512.3,\n",
        "            free_latency_p50=12.1,\n",
        "            free_latency_p95=35.6,\n",
        "            free_latency_p99=98.2,\n",
        "            free_latency_p999=245.8,\n",
        "            cross_thread_free_count=45_678,\n",
        "            cross_thread_free_pct=3.0,\n",
        "            size_histogram=SizeHistogram(\n",
        "                buckets={\n",
        "                    \"1-8\": 12345,\n",
        "                    \"9-16\": 45678,\n",
        "                    \"17-32\": 234567,\n",
        "                    \"33-64\": 567890,\n",
        "                    \"65-128\": 456789,\n",
        "                    \"129-256\": 123456,\n",
        "                    \"257-512\": 56789,\n",
        "                    \"513-1024\": 23456,\n",
        "                    \"1025-4096\": 2345,\n",
        "                    \"4097+\": 141,\n",
        "                },\n",
        "                total_count=1_523_456,\n",
        "                total_bytes=98_765_432,\n",
        "            ),\n",
        "            thread_stats=[\n",
        "                ThreadMemoryStats(1, \"MainThread\", 456789, 456700, 29876543, 29870000, 12345, 5678),\n",
        "                ThreadMemoryStats(2, \"Worker-1\", 234567, 234560, 15234567, 15230000, 8765, 3456),\n",
        "                ThreadMemoryStats(3, \"Worker-2\", 234567, 234560, 15234567, 15230000, 7654, 4567),\n",
        "                ThreadMemoryStats(4, \"Worker-3\", 198765, 198760, 12987654, 12980000, 6543, 5678),\n",
        "                ThreadMemoryStats(5, \"Worker-4\", 198765, 198760, 12987654, 12980000, 5432, 6789),\n",
        "                ThreadMemoryStats(6, \"Worker-5\", 100001, 100000, 6543210, 6540000, 4321, 7890),\n",
        "                ThreadMemoryStats(7, \"Worker-6\", 50001, 50000, 3456789, 3450000, 618, 8901),\n",
        "                ThreadMemoryStats(8, \"Worker-7\", 50001, 50000, 3456789, 3450000, 0, 2719),\n",
        "            ],\n",
        "            fragmentation=FragmentationMetrics(\n",
        "                internal_fragmentation=0.12,\n",
        "                external_fragmentation=0.05,\n",
        "                largest_free_block=1048576,\n",
        "                free_block_count=234,\n",
        "                utilization=0.83,\n",
        "            ),\n",
        "            leaked_allocations=None,\n",
        "            leaked_bytes=0,\n",
        "            duration_seconds=10.0,\n",
        "            start_time=datetime.now(),\n",
        "            end_time=datetime.now(),\n",
        "        )\n",
        "    \n",
        "    print(\"Simulation classes created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Workload Configuration\n",
        "\n",
        "Configure your test workload parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Workload parameters\n",
        "WORKLOAD_CONFIG = {\n",
        "    'num_threads': 8,\n",
        "    'operations_per_thread': 100_000,\n",
        "    'key_range': 50_000,\n",
        "    'value_size_min': 10,\n",
        "    'value_size_max': 1000,\n",
        "    'read_ratio': 0.7,  # 70% reads, 30% writes\n",
        "    'delete_ratio': 0.1,  # 10% of writes are deletes\n",
        "}\n",
        "\n",
        "print(\"Workload Configuration:\")\n",
        "for key, value in WORKLOAD_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Profiled Workload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if LIBRARY_AVAILABLE:\n",
        "    def run_workload():\n",
        "        \"\"\"Run the configured workload with profiling.\"\"\"\n",
        "        m = SkipListMap()\n",
        "        \n",
        "        def worker(thread_id):\n",
        "            for i in range(WORKLOAD_CONFIG['operations_per_thread']):\n",
        "                key = f\"key_{random.randint(0, WORKLOAD_CONFIG['key_range'])}\"\\n\",\n",
        "                \n",
        "                if random.random() < WORKLOAD_CONFIG['read_ratio']:\n",
        "                    _ = m.get(key)\n",
        "                else:\n",
        "                    if random.random() < WORKLOAD_CONFIG['delete_ratio']:\n",
        "                        m.pop(key, None)\n",
        "                    else:\n",
        "                        size = random.randint(\n",
        "                            WORKLOAD_CONFIG['value_size_min'],\n",
        "                            WORKLOAD_CONFIG['value_size_max']\n",
        "                        )\n",
        "                        m[key] = 'x' * size\n",
        "        \n",
        "        with MemoryProfiler(\n",
        "            track_sizes=True,\n",
        "            track_latency=True,\n",
        "            track_per_thread=True,\n",
        "            track_cross_thread=True,\n",
        "        ) as prof:\n",
        "            threads = [\n",
        "                threading.Thread(target=worker, args=(i,), name=f\"Worker-{i}\")\n",
        "                for i in range(WORKLOAD_CONFIG['num_threads'])\n",
        "            ]\n",
        "            \n",
        "            start = time.perf_counter()\n",
        "            for t in threads:\n",
        "                t.start()\n",
        "            for t in threads:\n",
        "                t.join()\n",
        "            elapsed = time.perf_counter() - start\n",
        "        \n",
        "        return prof.report(), elapsed\n",
        "    \n",
        "    print(\"Running workload...\")\n",
        "    report, elapsed = run_workload()\n",
        "    print(f\"Completed in {elapsed:.2f} seconds\")\n",
        "else:\n",
        "    print(\"Using simulated data...\")\n",
        "    report = generate_simulated_report()\n",
        "    elapsed = report.duration_seconds\n",
        "    print(f\"Simulated {report.duration_seconds:.2f} seconds of profiling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"MEMORY PROFILER RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n### Allocation Statistics ###\")\n",
        "print(f\"Total allocations: {report.alloc_count:,}\")\n",
        "print(f\"Total frees: {report.free_count:,}\")\n",
        "print(f\"Total bytes allocated: {report.alloc_bytes / 1024**2:.2f} MB\")\n",
        "print(f\"Peak memory: {report.peak_allocated / 1024**2:.2f} MB\")\n",
        "print(f\"Current allocated: {report.current_allocated / 1024:.2f} KB\")\n",
        "\n",
        "print(f\"\\n### Throughput ###\")\n",
        "print(f\"Allocation rate: {report.alloc_rate:,.0f} allocs/sec\")\n",
        "print(f\"Free rate: {report.free_rate:,.0f} frees/sec\")\n",
        "print(f\"Byte rate: {report.bytes_rate / 1024**2:.2f} MB/sec\")\n",
        "\n",
        "print(f\"\\n### Latency (nanoseconds) ###\")\n",
        "print(f\"Alloc P50: {report.alloc_latency_p50:.1f} ns\")\n",
        "print(f\"Alloc P95: {report.alloc_latency_p95:.1f} ns\")\n",
        "print(f\"Alloc P99: {report.alloc_latency_p99:.1f} ns\")\n",
        "print(f\"Alloc P99.9: {report.alloc_latency_p999:.1f} ns\")\n",
        "print(f\"Free P99: {report.free_latency_p99:.1f} ns\")\n",
        "\n",
        "print(f\"\\n### Cross-Thread Operations ###\")\n",
        "print(f\"Cross-thread frees: {report.cross_thread_free_count:,}\")\n",
        "print(f\"Cross-thread percentage: {report.cross_thread_free_pct:.2f}%\")\n",
        "\n",
        "print(f\"\\n### Fragmentation ###\")\n",
        "print(f\"Internal fragmentation: {report.fragmentation.internal_fragmentation:.1%}\")\n",
        "print(f\"External fragmentation: {report.fragmentation.external_fragmentation:.1%}\")\n",
        "print(f\"Memory utilization: {report.fragmentation.utilization:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Allocation Size Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Allocation Size Distribution ###\\n\")\n",
        "print(f\"{'Size Range':<15} {'Count':>12} {'Percentage':>12}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "total = report.size_histogram.total_count\n",
        "for size_range, count in sorted(report.size_histogram.buckets.items(), \n",
        "                                 key=lambda x: int(x[0].split('-')[0].replace('+', ''))):\n",
        "    pct = (count / total) * 100 if total > 0 else 0\n",
        "    bar = '#' * int(pct / 2)\n",
        "    print(f\"{size_range:<15} {count:>12,} {pct:>10.1f}% {bar}\")\n",
        "\n",
        "print(f\"\\n### Hot Allocation Sizes ###\")\n",
        "print(\"These sizes are most frequently allocated:\")\n",
        "for i, (size_range, count) in enumerate(report.size_histogram.hot_sizes(5), 1):\n",
        "    pct = (count / total) * 100\n",
        "    print(f\"  {i}. {size_range}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Per-Thread Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Per-Thread Memory Statistics ###\\n\")\n",
        "\n",
        "# Sort by allocation count\n",
        "sorted_threads = sorted(report.thread_stats, key=lambda x: -x.alloc_count)\n",
        "\n",
        "print(f\"{'Thread':<15} {'Allocs':>10} {'Frees':>10} {'Bytes':>12} {'X-Thread Sent':>14}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for ts in sorted_threads:\n",
        "    name = ts.thread_name or f\"Thread-{ts.thread_id}\"\n",
        "    print(f\"{name:<15} {ts.alloc_count:>10,} {ts.free_count:>10,} \"\n",
        "          f\"{ts.alloc_bytes/1024:>10,.0f}KB {ts.cross_thread_frees_sent:>14,}\")\n",
        "\n",
        "# Cross-thread analysis\n",
        "print(f\"\\n### Cross-Thread Free Pattern ###\")\n",
        "total_sent = sum(ts.cross_thread_frees_sent for ts in report.thread_stats)\n",
        "total_received = sum(ts.cross_thread_frees_received for ts in report.thread_stats)\n",
        "print(f\"Total cross-thread frees sent: {total_sent:,}\")\n",
        "print(f\"Total cross-thread frees received: {total_received:,}\")\n",
        "\n",
        "# Find imbalances\n",
        "print(f\"\\nThreads with high cross-thread activity:\")\n",
        "for ts in sorted_threads:\n",
        "    if ts.cross_thread_frees_sent > 0:\n",
        "        ratio = ts.cross_thread_frees_sent / ts.alloc_count * 100 if ts.alloc_count > 0 else 0\n",
        "        if ratio > 1:  # More than 1% cross-thread\n",
        "            name = ts.thread_name or f\"Thread-{ts.thread_id}\"\n",
        "            print(f\"  {name}: {ratio:.1f}% of allocations freed by other threads\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    PLOTTING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PLOTTING_AVAILABLE = False\n",
        "    print(\"matplotlib not available - skipping visualizations\")\n",
        "    print(\"Install with: pip install matplotlib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PLOTTING_AVAILABLE:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Size distribution bar chart\n",
        "    ax1 = axes[0, 0]\n",
        "    sizes = list(report.size_histogram.buckets.keys())\n",
        "    counts = list(report.size_histogram.buckets.values())\n",
        "    ax1.bar(range(len(sizes)), counts, color='steelblue')\n",
        "    ax1.set_xticks(range(len(sizes)))\n",
        "    ax1.set_xticklabels(sizes, rotation=45, ha='right')\n",
        "    ax1.set_xlabel('Size Range (bytes)')\n",
        "    ax1.set_ylabel('Count')\n",
        "    ax1.set_title('Allocation Size Distribution')\n",
        "    ax1.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
        "    \n",
        "    # 2. Per-thread allocation pie chart\n",
        "    ax2 = axes[0, 1]\n",
        "    thread_names = [ts.thread_name or f\"T{ts.thread_id}\" for ts in report.thread_stats]\n",
        "    thread_allocs = [ts.alloc_count for ts in report.thread_stats]\n",
        "    ax2.pie(thread_allocs, labels=thread_names, autopct='%1.1f%%', startangle=90)\n",
        "    ax2.set_title('Allocations by Thread')\n",
        "    \n",
        "    # 3. Latency comparison\n",
        "    ax3 = axes[1, 0]\n",
        "    percentiles = ['P50', 'P95', 'P99', 'P99.9']\n",
        "    alloc_latencies = [\n",
        "        report.alloc_latency_p50,\n",
        "        report.alloc_latency_p95,\n",
        "        report.alloc_latency_p99,\n",
        "        report.alloc_latency_p999,\n",
        "    ]\n",
        "    free_latencies = [\n",
        "        report.free_latency_p50,\n",
        "        report.free_latency_p95,\n",
        "        report.free_latency_p99,\n",
        "        report.free_latency_p999,\n",
        "    ]\n",
        "    x = np.arange(len(percentiles))\n",
        "    width = 0.35\n",
        "    ax3.bar(x - width/2, alloc_latencies, width, label='Alloc', color='coral')\n",
        "    ax3.bar(x + width/2, free_latencies, width, label='Free', color='mediumseagreen')\n",
        "    ax3.set_xticks(x)\n",
        "    ax3.set_xticklabels(percentiles)\n",
        "    ax3.set_xlabel('Percentile')\n",
        "    ax3.set_ylabel('Latency (ns)')\n",
        "    ax3.set_title('Allocation vs Free Latency')\n",
        "    ax3.legend()\n",
        "    ax3.set_yscale('log')\n",
        "    \n",
        "    # 4. Cross-thread free flow\n",
        "    ax4 = axes[1, 1]\n",
        "    sent = [ts.cross_thread_frees_sent for ts in report.thread_stats]\n",
        "    received = [ts.cross_thread_frees_received for ts in report.thread_stats]\n",
        "    x = np.arange(len(thread_names))\n",
        "    ax4.bar(x - width/2, sent, width, label='Sent', color='indianred')\n",
        "    ax4.bar(x + width/2, received, width, label='Received', color='dodgerblue')\n",
        "    ax4.set_xticks(x)\n",
        "    ax4.set_xticklabels(thread_names, rotation=45, ha='right')\n",
        "    ax4.set_xlabel('Thread')\n",
        "    ax4.set_ylabel('Count')\n",
        "    ax4.set_title('Cross-Thread Free Pattern')\n",
        "    ax4.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('memory_profile_charts.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\nCharts saved to memory_profile_charts.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recommendations(report):\n",
        "    \"\"\"Generate optimization recommendations based on profiling data.\"\"\"\n",
        "    recommendations = []\n",
        "    \n",
        "    # Check allocation latency\n",
        "    if report.alloc_latency_p99 > 500:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Latency',\n",
        "            'issue': f'High allocation latency: P99 = {report.alloc_latency_p99:.0f}ns',\n",
        "            'recommendation': 'Consider pre-allocating memory pools for hot paths',\n",
        "        })\n",
        "    \n",
        "    # Check cross-thread free percentage\n",
        "    if report.cross_thread_free_pct > 10:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Cross-Thread',\n",
        "            'issue': f'High cross-thread free rate: {report.cross_thread_free_pct:.1f}%',\n",
        "            'recommendation': 'Consider thread-affinity for allocation/free patterns',\n",
        "        })\n",
        "    elif report.cross_thread_free_pct > 5:\n",
        "        recommendations.append({\n",
        "            'severity': 'info',\n",
        "            'category': 'Cross-Thread',\n",
        "            'issue': f'Moderate cross-thread free rate: {report.cross_thread_free_pct:.1f}%',\n",
        "            'recommendation': 'Cross-thread frees are normal for concurrent data structures',\n",
        "        })\n",
        "    \n",
        "    # Check fragmentation\n",
        "    if report.fragmentation.internal_fragmentation > 0.2:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Fragmentation',\n",
        "            'issue': f'High internal fragmentation: {report.fragmentation.internal_fragmentation:.1%}',\n",
        "            'recommendation': 'Use size classes that match your allocation patterns',\n",
        "        })\n",
        "    \n",
        "    if report.fragmentation.external_fragmentation > 0.15:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Fragmentation',\n",
        "            'issue': f'High external fragmentation: {report.fragmentation.external_fragmentation:.1%}',\n",
        "            'recommendation': 'Consider memory compaction or arena allocation',\n",
        "        })\n",
        "    \n",
        "    # Check for memory leaks\n",
        "    if report.leaked_bytes > 0:\n",
        "        recommendations.append({\n",
        "            'severity': 'error',\n",
        "            'category': 'Leak',\n",
        "            'issue': f'Memory leak detected: {report.leaked_bytes:,} bytes',\n",
        "            'recommendation': 'Enable stack traces to identify leak sources',\n",
        "        })\n",
        "    \n",
        "    # Check size distribution\n",
        "    hot_sizes = report.size_histogram.hot_sizes(3)\n",
        "    if hot_sizes:\n",
        "        top_size, top_count = hot_sizes[0]\n",
        "        top_pct = (top_count / report.size_histogram.total_count) * 100\n",
        "        if top_pct > 50:\n",
        "            recommendations.append({\n",
        "                'severity': 'info',\n",
        "                'category': 'Size Distribution',\n",
        "                'issue': f'Dominant allocation size: {top_size} ({top_pct:.0f}% of allocations)',\n",
        "                'recommendation': 'Consider a specialized allocator for this size class',\n",
        "            })\n",
        "    \n",
        "    # Check utilization\n",
        "    if report.fragmentation.utilization < 0.7:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Utilization',\n",
        "            'issue': f'Low memory utilization: {report.fragmentation.utilization:.1%}',\n",
        "            'recommendation': 'Memory is underutilized; consider reducing heap size',\n",
        "        })\n",
        "    \n",
        "    # If everything looks good\n",
        "    if not recommendations:\n",
        "        recommendations.append({\n",
        "            'severity': 'success',\n",
        "            'category': 'Overall',\n",
        "            'issue': 'No significant issues detected',\n",
        "            'recommendation': 'Memory allocation patterns look healthy',\n",
        "        })\n",
        "    \n",
        "    return recommendations\n",
        "\n",
        "# Generate and display recommendations\n",
        "recommendations = generate_recommendations(report)\n",
        "\n",
        "severity_icons = {\n",
        "    'error': '\\U0001F534',    # Red circle\n",
        "    'warning': '\\U0001F7E0',  # Orange circle\n",
        "    'info': '\\U0001F7E1',     # Yellow circle\n",
        "    'success': '\\u2705',      # Green checkmark\n",
        "}\n",
        "\n",
        "print(\"### Recommendations ###\\n\")\n",
        "for rec in recommendations:\n",
        "    icon = severity_icons.get(rec['severity'], '')\n",
        "    print(f\"{icon} [{rec['category']}] {rec['issue']}\")\n",
        "    print(f\"   Recommendation: {rec['recommendation']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from dataclasses import asdict\n",
        "\n",
        "def export_report(report, filename='memory_profile_report.json'):\n",
        "    \"\"\"Export report to JSON.\"\"\"\n",
        "    # Convert to dict (handling nested dataclasses)\n",
        "    def to_dict(obj):\n",
        "        if hasattr(obj, '__dataclass_fields__'):\n",
        "            return {k: to_dict(v) for k, v in asdict(obj).items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [to_dict(item) for item in obj]\n",
        "        elif isinstance(obj, datetime):\n",
        "            return obj.isoformat()\n",
        "        else:\n",
        "            return obj\n",
        "    \n",
        "    data = to_dict(report)\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f, indent=2, default=str)\n",
        "    \n",
        "    print(f\"Report exported to {filename}\")\n",
        "\n",
        "# Export\n",
        "export_report(report)\n",
        "\n",
        "# Also export recommendations\n",
        "with open('memory_recommendations.json', 'w') as f:\n",
        "    json.dump(recommendations, f, indent=2)\n",
        "print(\"Recommendations exported to memory_recommendations.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook analyzed memory allocation patterns and provided:\n",
        "\n",
        "1. **Basic Statistics** - Allocation counts, bytes, rates\n",
        "2. **Latency Analysis** - P50/P95/P99/P99.9 for alloc and free\n",
        "3. **Size Distribution** - Which sizes are most commonly allocated\n",
        "4. **Per-Thread Analysis** - Memory usage by thread\n",
        "5. **Cross-Thread Patterns** - How memory flows between threads\n",
        "6. **Fragmentation Metrics** - Internal and external fragmentation\n",
        "7. **Visualizations** - Charts for quick understanding\n",
        "8. **Recommendations** - Actionable optimization suggestions\n",
        "\n",
        "For more advanced analysis, see:\n",
        "- `smr_performance_analysis.ipynb` - SMR-specific profiling\n",
        "- `memory_subsystem_comparison.ipynb` - Compare IBR vs DEBRA+"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
