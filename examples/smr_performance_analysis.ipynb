{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMR Performance Analysis\n",
        "\n",
        "Interactive analysis of Safe Memory Reclamation (SMR) behavior using `SMRProfiler`.\n",
        "\n",
        "This notebook helps you:\n",
        "- Understand epoch advancement patterns\n",
        "- Identify stalled threads blocking reclamation\n",
        "- Analyze reclamation latency\n",
        "- Monitor memory pressure\n",
        "- Optimize SMR configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from typing import Optional, List\n",
        "\n",
        "try:\n",
        "    from concurrent_collections import SMRProfiler, SkipListMap, config\n",
        "    LIBRARY_AVAILABLE = True\n",
        "    print(f\"concurrent_collections loaded\")\n",
        "    print(f\"SMR scheme: {config.smr_scheme}\")\n",
        "except ImportError:\n",
        "    LIBRARY_AVAILABLE = False\n",
        "    print(\"Running in simulation mode\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Simulation Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LIBRARY_AVAILABLE:\n",
        "    @dataclass\n",
        "    class ThreadSMRStats:\n",
        "        thread_id: int\n",
        "        thread_name: Optional[str]\n",
        "        enter_count: int\n",
        "        exit_count: int\n",
        "        retire_count: int\n",
        "        poll_count: int\n",
        "        reclaim_count: int\n",
        "        total_cs_time_ns: int\n",
        "        avg_cs_time_ns: float\n",
        "        max_cs_time_ns: int\n",
        "        peak_limbo_count: int\n",
        "        peak_limbo_bytes: int\n",
        "        stall_count: int\n",
        "        caused_stall_epochs: int\n",
        "    \n",
        "    @dataclass\n",
        "    class StallEvent:\n",
        "        timestamp: float\n",
        "        stalled_thread_id: int\n",
        "        stalled_at_epoch: int\n",
        "        global_epoch: int\n",
        "        epoch_lag: int\n",
        "        duration_ns: Optional[int]\n",
        "        resolution: str\n",
        "    \n",
        "    @dataclass\n",
        "    class SMRProfilerReport:\n",
        "        start_epoch: int\n",
        "        end_epoch: int\n",
        "        epoch_advances: int\n",
        "        avg_epoch_duration_ns: float\n",
        "        safe_epoch_lag_avg: float\n",
        "        safe_epoch_lag_max: int\n",
        "        total_retired: int\n",
        "        total_reclaimed: int\n",
        "        pending_count: int\n",
        "        pending_bytes: int\n",
        "        reclaim_latency_p50: float\n",
        "        reclaim_latency_p95: float\n",
        "        reclaim_latency_p99: float\n",
        "        reclaim_latency_p999: float\n",
        "        reclaim_latency_max: float\n",
        "        poll_count: int\n",
        "        nodes_per_poll_avg: float\n",
        "        nodes_per_poll_max: int\n",
        "        empty_poll_pct: float\n",
        "        peak_pending_count: int\n",
        "        peak_pending_bytes: int\n",
        "        memory_bound_utilization: float\n",
        "        thread_stats: List[ThreadSMRStats]\n",
        "        stall_events: List[StallEvent]\n",
        "        total_stall_time_ns: int\n",
        "        stall_count: int\n",
        "        epoch_timeline: Optional[list]\n",
        "        limbo_snapshots: Optional[list]\n",
        "        duration_seconds: float\n",
        "        start_time: datetime\n",
        "        end_time: datetime\n",
        "\n",
        "    def generate_simulated_smr_report():\n",
        "        \"\"\"Generate realistic simulated SMR data.\"\"\"\n",
        "        thread_stats = [\n",
        "            ThreadSMRStats(1, \"MainThread\", 50000, 50000, 25000, 500, 24500, \n",
        "                          500000000, 10000, 150000, 128, 8192, 0, 0),\n",
        "            ThreadSMRStats(2, \"Worker-1\", 45000, 45000, 22000, 450, 21500,\n",
        "                          450000000, 10000, 120000, 115, 7360, 1, 5),\n",
        "            ThreadSMRStats(3, \"Worker-2\", 48000, 48000, 24000, 480, 23500,\n",
        "                          480000000, 10000, 180000, 122, 7808, 0, 0),\n",
        "            ThreadSMRStats(4, \"Worker-3\", 42000, 42000, 21000, 420, 20500,\n",
        "                          420000000, 10000, 200000, 108, 6912, 2, 12),\n",
        "            ThreadSMRStats(5, \"Worker-4\", 46000, 46000, 23000, 460, 22500,\n",
        "                          460000000, 10000, 140000, 118, 7552, 0, 0),\n",
        "            ThreadSMRStats(6, \"Worker-5\", 44000, 44000, 22000, 440, 21500,\n",
        "                          440000000, 10000, 160000, 112, 7168, 1, 3),\n",
        "            ThreadSMRStats(7, \"Worker-6\", 47000, 47000, 23500, 470, 23000,\n",
        "                          470000000, 10000, 130000, 120, 7680, 0, 0),\n",
        "            ThreadSMRStats(8, \"Worker-7\", 43000, 43000, 21500, 430, 21000,\n",
        "                          430000000, 10000, 170000, 110, 7040, 1, 2),\n",
        "        ]\n",
        "        \n",
        "        stall_events = [\n",
        "            StallEvent(1.234, 2, 1000, 1015, 15, 50000000, \"exited\"),\n",
        "            StallEvent(3.456, 4, 2500, 2520, 20, 80000000, \"exited\"),\n",
        "            StallEvent(5.678, 4, 4000, 4018, 18, 60000000, \"exited\"),\n",
        "            StallEvent(7.890, 6, 5500, 5512, 12, 40000000, \"exited\"),\n",
        "            StallEvent(9.012, 8, 7000, 7010, 10, 30000000, \"exited\"),\n",
        "        ]\n",
        "        \n",
        "        return SMRProfilerReport(\n",
        "            start_epoch=1,\n",
        "            end_epoch=12345,\n",
        "            epoch_advances=12344,\n",
        "            avg_epoch_duration_ns=810500,\n",
        "            safe_epoch_lag_avg=1.2,\n",
        "            safe_epoch_lag_max=20,\n",
        "            total_retired=182000,\n",
        "            total_reclaimed=181950,\n",
        "            pending_count=50,\n",
        "            pending_bytes=3200,\n",
        "            reclaim_latency_p50=5000,\n",
        "            reclaim_latency_p95=25000,\n",
        "            reclaim_latency_p99=100000,\n",
        "            reclaim_latency_p999=500000,\n",
        "            reclaim_latency_max=2000000,\n",
        "            poll_count=3600,\n",
        "            nodes_per_poll_avg=50.5,\n",
        "            nodes_per_poll_max=128,\n",
        "            empty_poll_pct=12.5,\n",
        "            peak_pending_count=512,\n",
        "            peak_pending_bytes=32768,\n",
        "            memory_bound_utilization=0.67,\n",
        "            thread_stats=thread_stats,\n",
        "            stall_events=stall_events,\n",
        "            total_stall_time_ns=260000000,\n",
        "            stall_count=5,\n",
        "            epoch_timeline=None,\n",
        "            limbo_snapshots=None,\n",
        "            duration_seconds=10.0,\n",
        "            start_time=datetime.now(),\n",
        "            end_time=datetime.now(),\n",
        "        )\n",
        "    \n",
        "    print(\"Simulation classes created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Workload Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORKLOAD_CONFIG = {\n",
        "    'num_threads': 8,\n",
        "    'operations_per_thread': 50_000,\n",
        "    'key_range': 25_000,\n",
        "    'delete_ratio': 0.3,  # Higher delete ratio to stress SMR\n",
        "    'stall_probability': 0.001,  # 0.1% chance of brief stall\n",
        "    'stall_duration_ms': 5,\n",
        "}\n",
        "\n",
        "print(\"Workload Configuration:\")\n",
        "for key, value in WORKLOAD_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Profiled Workload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if LIBRARY_AVAILABLE:\n",
        "    def run_smr_workload():\n",
        "        m = SkipListMap()\n",
        "        \n",
        "        def worker(thread_id):\n",
        "            for i in range(WORKLOAD_CONFIG['operations_per_thread']):\n",
        "                key = f\"key_{random.randint(0, WORKLOAD_CONFIG['key_range'])}\"\n",
        "                \n",
        "                # Occasional stall to trigger SMR pressure\n",
        "                if random.random() < WORKLOAD_CONFIG['stall_probability']:\n",
        "                    time.sleep(WORKLOAD_CONFIG['stall_duration_ms'] / 1000)\n",
        "                \n",
        "                if random.random() < WORKLOAD_CONFIG['delete_ratio']:\n",
        "                    m.pop(key, None)  # Delete triggers SMR retire\n",
        "                else:\n",
        "                    m[key] = f\"value_{i}\"\n",
        "        \n",
        "        with SMRProfiler(\n",
        "            track_per_thread=True,\n",
        "            track_latency=True,\n",
        "            stall_threshold_epochs=10,\n",
        "        ) as prof:\n",
        "            threads = [\n",
        "                threading.Thread(target=worker, args=(i,), name=f\"Worker-{i}\")\n",
        "                for i in range(WORKLOAD_CONFIG['num_threads'])\n",
        "            ]\n",
        "            \n",
        "            for t in threads:\n",
        "                t.start()\n",
        "            for t in threads:\n",
        "                t.join()\n",
        "        \n",
        "        return prof.report()\n",
        "    \n",
        "    print(\"Running SMR workload...\")\n",
        "    report = run_smr_workload()\n",
        "    print(f\"Completed in {report.duration_seconds:.2f} seconds\")\n",
        "else:\n",
        "    print(\"Using simulated data...\")\n",
        "    report = generate_simulated_smr_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Epoch Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SMR PROFILER RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n### Epoch Statistics ###\")\n",
        "print(f\"Start epoch: {report.start_epoch:,}\")\n",
        "print(f\"End epoch: {report.end_epoch:,}\")\n",
        "print(f\"Epoch advances: {report.epoch_advances:,}\")\n",
        "print(f\"Avg epoch duration: {report.avg_epoch_duration_ns / 1000:.1f} ¬µs\")\n",
        "print(f\"Epoch advance rate: {report.epoch_advances / report.duration_seconds:.0f} epochs/sec\")\n",
        "\n",
        "print(f\"\\n### Safe Epoch Lag ###\")\n",
        "print(f\"Average lag: {report.safe_epoch_lag_avg:.2f} epochs\")\n",
        "print(f\"Maximum lag: {report.safe_epoch_lag_max} epochs\")\n",
        "\n",
        "if report.safe_epoch_lag_max > 10:\n",
        "    print(f\"  ‚ö†Ô∏è High epoch lag detected - some threads may be stalling\")\n",
        "else:\n",
        "    print(f\"  ‚úÖ Epoch lag is within normal range\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Reclamation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Reclamation Statistics ###\")\n",
        "print(f\"\\nTotal retired: {report.total_retired:,} nodes\")\n",
        "print(f\"Total reclaimed: {report.total_reclaimed:,} nodes\")\n",
        "print(f\"Currently pending: {report.pending_count:,} nodes ({report.pending_bytes:,} bytes)\")\n",
        "print(f\"Peak pending: {report.peak_pending_count:,} nodes ({report.peak_pending_bytes:,} bytes)\")\n",
        "\n",
        "reclaim_rate = report.total_reclaimed / report.total_retired * 100 if report.total_retired > 0 else 0\n",
        "print(f\"Reclamation efficiency: {reclaim_rate:.1f}%\")\n",
        "\n",
        "print(f\"\\n### Reclamation Latency (retire ‚Üí free) ###\")\n",
        "print(f\"P50:   {report.reclaim_latency_p50 / 1000:>8.1f} ¬µs\")\n",
        "print(f\"P95:   {report.reclaim_latency_p95 / 1000:>8.1f} ¬µs\")\n",
        "print(f\"P99:   {report.reclaim_latency_p99 / 1000:>8.1f} ¬µs\")\n",
        "print(f\"P99.9: {report.reclaim_latency_p999 / 1000:>8.1f} ¬µs\")\n",
        "print(f\"Max:   {report.reclaim_latency_max / 1000:>8.1f} ¬µs\")\n",
        "\n",
        "print(f\"\\n### Poll Statistics ###\")\n",
        "print(f\"Total polls: {report.poll_count:,}\")\n",
        "print(f\"Nodes per poll (avg): {report.nodes_per_poll_avg:.1f}\")\n",
        "print(f\"Nodes per poll (max): {report.nodes_per_poll_max}\")\n",
        "print(f\"Empty polls: {report.empty_poll_pct:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Memory Pressure Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Memory Pressure ###\")\n",
        "print(f\"\\nMemory bound utilization: {report.memory_bound_utilization:.1%}\")\n",
        "\n",
        "# Calculate theoretical bounds\n",
        "T = len(report.thread_stats)\n",
        "R = 64  # Default retire threshold\n",
        "theoretical_max = 3 * T * R\n",
        "\n",
        "print(f\"\\nTheoretical bounds:\")\n",
        "print(f\"  Threads (T): {T}\")\n",
        "print(f\"  Retire threshold (R): {R}\")\n",
        "print(f\"  Theoretical max (3√óT√óR): {theoretical_max:,} nodes\")\n",
        "print(f\"  Actual peak: {report.peak_pending_count:,} nodes\")\n",
        "print(f\"  Headroom: {((theoretical_max - report.peak_pending_count) / theoretical_max * 100):.1f}%\")\n",
        "\n",
        "if report.memory_bound_utilization > 0.8:\n",
        "    print(f\"\\n‚ö†Ô∏è Memory pressure is HIGH\")\n",
        "    print(f\"   Consider: increasing retire threshold, reducing thread count, or using DEBRA+\")\n",
        "elif report.memory_bound_utilization > 0.5:\n",
        "    print(f\"\\nüü° Memory pressure is MODERATE\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Memory pressure is LOW\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Stall Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Stall Analysis ###\")\n",
        "print(f\"\\nTotal stall events: {report.stall_count}\")\n",
        "print(f\"Total stall time: {report.total_stall_time_ns / 1e6:.1f} ms\")\n",
        "\n",
        "if report.stall_events:\n",
        "    print(f\"\\nStall events:\")\n",
        "    print(f\"{'Time':>8} {'Thread':>8} {'At Epoch':>10} {'Global':>10} {'Lag':>6} {'Duration':>10} {'Resolution'}\")\n",
        "    print(\"-\" * 75)\n",
        "    \n",
        "    for stall in report.stall_events:\n",
        "        duration = f\"{stall.duration_ns / 1e6:.1f}ms\" if stall.duration_ns else \"ongoing\"\n",
        "        print(f\"{stall.timestamp:>8.2f} {stall.stalled_thread_id:>8} {stall.stalled_at_epoch:>10,} \"\n",
        "              f\"{stall.global_epoch:>10,} {stall.epoch_lag:>6} {duration:>10} {stall.resolution}\")\n",
        "    \n",
        "    # Analyze stall patterns\n",
        "    stall_by_thread = {}\n",
        "    for stall in report.stall_events:\n",
        "        tid = stall.stalled_thread_id\n",
        "        if tid not in stall_by_thread:\n",
        "            stall_by_thread[tid] = []\n",
        "        stall_by_thread[tid].append(stall)\n",
        "    \n",
        "    print(f\"\\nStalls by thread:\")\n",
        "    for tid, stalls in sorted(stall_by_thread.items(), key=lambda x: -len(x[1])):\n",
        "        total_time = sum(s.duration_ns or 0 for s in stalls)\n",
        "        print(f\"  Thread {tid}: {len(stalls)} stalls, {total_time / 1e6:.1f}ms total\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No stall events detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Per-Thread Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"### Per-Thread SMR Statistics ###\\n\")\n",
        "\n",
        "# Sort by retire count\n",
        "sorted_threads = sorted(report.thread_stats, key=lambda x: -x.retire_count)\n",
        "\n",
        "print(f\"{'Thread':<12} {'Enter':>8} {'Retire':>8} {'Reclaim':>8} {'Avg CS':>10} {'Stalls':>7}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for ts in sorted_threads:\n",
        "    name = ts.thread_name or f\"Thread-{ts.thread_id}\"\n",
        "    avg_cs = f\"{ts.avg_cs_time_ns / 1000:.1f}¬µs\"\n",
        "    print(f\"{name:<12} {ts.enter_count:>8,} {ts.retire_count:>8,} {ts.reclaim_count:>8,} \"\n",
        "          f\"{avg_cs:>10} {ts.stall_count:>7}\")\n",
        "\n",
        "# Find problematic threads\n",
        "print(f\"\\n### Thread Health ###\")\n",
        "for ts in sorted_threads:\n",
        "    name = ts.thread_name or f\"Thread-{ts.thread_id}\"\n",
        "    issues = []\n",
        "    \n",
        "    if ts.stall_count > 0:\n",
        "        issues.append(f\"{ts.stall_count} stalls\")\n",
        "    if ts.caused_stall_epochs > 5:\n",
        "        issues.append(f\"blocked {ts.caused_stall_epochs} epoch advances\")\n",
        "    if ts.max_cs_time_ns > 1000000:  # > 1ms\n",
        "        issues.append(f\"max CS time {ts.max_cs_time_ns / 1e6:.1f}ms\")\n",
        "    \n",
        "    if issues:\n",
        "        print(f\"  ‚ö†Ô∏è {name}: {', '.join(issues)}\")\n",
        "\n",
        "if all(ts.stall_count == 0 and ts.caused_stall_epochs < 5 for ts in sorted_threads):\n",
        "    print(f\"  ‚úÖ All threads operating normally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    PLOTTING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PLOTTING_AVAILABLE = False\n",
        "    print(\"matplotlib not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PLOTTING_AVAILABLE:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Reclamation latency distribution\n",
        "    ax1 = axes[0, 0]\n",
        "    percentiles = ['P50', 'P95', 'P99', 'P99.9', 'Max']\n",
        "    latencies = [\n",
        "        report.reclaim_latency_p50 / 1000,\n",
        "        report.reclaim_latency_p95 / 1000,\n",
        "        report.reclaim_latency_p99 / 1000,\n",
        "        report.reclaim_latency_p999 / 1000,\n",
        "        report.reclaim_latency_max / 1000,\n",
        "    ]\n",
        "    colors = ['green', 'yellowgreen', 'orange', 'orangered', 'red']\n",
        "    ax1.bar(percentiles, latencies, color=colors)\n",
        "    ax1.set_ylabel('Latency (¬µs)')\n",
        "    ax1.set_title('Reclamation Latency Distribution')\n",
        "    ax1.set_yscale('log')\n",
        "    \n",
        "    # 2. Per-thread retire/reclaim\n",
        "    ax2 = axes[0, 1]\n",
        "    thread_names = [ts.thread_name or f\"T{ts.thread_id}\" for ts in report.thread_stats]\n",
        "    retire_counts = [ts.retire_count for ts in report.thread_stats]\n",
        "    reclaim_counts = [ts.reclaim_count for ts in report.thread_stats]\n",
        "    x = np.arange(len(thread_names))\n",
        "    width = 0.35\n",
        "    ax2.bar(x - width/2, retire_counts, width, label='Retired', color='coral')\n",
        "    ax2.bar(x + width/2, reclaim_counts, width, label='Reclaimed', color='mediumseagreen')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(thread_names, rotation=45, ha='right')\n",
        "    ax2.set_ylabel('Count')\n",
        "    ax2.set_title('Retire vs Reclaim by Thread')\n",
        "    ax2.legend()\n",
        "    \n",
        "    # 3. Critical section time\n",
        "    ax3 = axes[1, 0]\n",
        "    avg_cs_times = [ts.avg_cs_time_ns / 1000 for ts in report.thread_stats]\n",
        "    max_cs_times = [ts.max_cs_time_ns / 1000 for ts in report.thread_stats]\n",
        "    ax3.bar(x - width/2, avg_cs_times, width, label='Avg', color='steelblue')\n",
        "    ax3.bar(x + width/2, max_cs_times, width, label='Max', color='indianred')\n",
        "    ax3.set_xticks(x)\n",
        "    ax3.set_xticklabels(thread_names, rotation=45, ha='right')\n",
        "    ax3.set_ylabel('Time (¬µs)')\n",
        "    ax3.set_title('Critical Section Duration by Thread')\n",
        "    ax3.legend()\n",
        "    ax3.set_yscale('log')\n",
        "    \n",
        "    # 4. Memory pressure gauge\n",
        "    ax4 = axes[1, 1]\n",
        "    utilization = report.memory_bound_utilization\n",
        "    colors_gauge = ['green' if utilization < 0.5 else 'orange' if utilization < 0.8 else 'red']\n",
        "    ax4.barh(['Memory Bound\\nUtilization'], [utilization], color=colors_gauge, height=0.5)\n",
        "    ax4.barh(['Memory Bound\\nUtilization'], [1 - utilization], left=[utilization], \n",
        "             color='lightgray', height=0.5)\n",
        "    ax4.set_xlim(0, 1)\n",
        "    ax4.set_xlabel('Utilization')\n",
        "    ax4.set_title(f'Memory Pressure: {utilization:.1%}')\n",
        "    ax4.axvline(x=0.5, color='orange', linestyle='--', alpha=0.5)\n",
        "    ax4.axvline(x=0.8, color='red', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('smr_profile_charts.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Charts saved to smr_profile_charts.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_smr_recommendations(report):\n",
        "    recommendations = []\n",
        "    \n",
        "    # Check epoch lag\n",
        "    if report.safe_epoch_lag_max > 20:\n",
        "        recommendations.append({\n",
        "            'severity': 'error',\n",
        "            'category': 'Epoch Lag',\n",
        "            'issue': f'Very high epoch lag: {report.safe_epoch_lag_max} epochs',\n",
        "            'recommendation': 'Consider using DEBRA+ for automatic stall handling',\n",
        "        })\n",
        "    elif report.safe_epoch_lag_max > 10:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Epoch Lag',\n",
        "            'issue': f'High epoch lag: {report.safe_epoch_lag_max} epochs',\n",
        "            'recommendation': 'Identify stalling threads and reduce critical section time',\n",
        "        })\n",
        "    \n",
        "    # Check reclamation latency\n",
        "    if report.reclaim_latency_p99 > 1000000:  # > 1ms\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Latency',\n",
        "            'issue': f'High reclamation latency P99: {report.reclaim_latency_p99/1000:.0f}¬µs',\n",
        "            'recommendation': 'Increase poll frequency or reduce retire threshold',\n",
        "        })\n",
        "    \n",
        "    # Check memory pressure\n",
        "    if report.memory_bound_utilization > 0.8:\n",
        "        recommendations.append({\n",
        "            'severity': 'error',\n",
        "            'category': 'Memory',\n",
        "            'issue': f'Memory bound utilization: {report.memory_bound_utilization:.1%}',\n",
        "            'recommendation': 'Risk of hitting memory bound; reduce thread count or use DEBRA+',\n",
        "        })\n",
        "    elif report.memory_bound_utilization > 0.5:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Memory',\n",
        "            'issue': f'Moderate memory pressure: {report.memory_bound_utilization:.1%}',\n",
        "            'recommendation': 'Monitor for increases under higher load',\n",
        "        })\n",
        "    \n",
        "    # Check stalls\n",
        "    if report.stall_count > 10:\n",
        "        recommendations.append({\n",
        "            'severity': 'warning',\n",
        "            'category': 'Stalls',\n",
        "            'issue': f'{report.stall_count} stall events detected',\n",
        "            'recommendation': 'Reduce blocking operations in critical sections',\n",
        "        })\n",
        "    \n",
        "    # Check empty polls\n",
        "    if report.empty_poll_pct > 30:\n",
        "        recommendations.append({\n",
        "            'severity': 'info',\n",
        "            'category': 'Efficiency',\n",
        "            'issue': f'{report.empty_poll_pct:.0f}% of polls found nothing to reclaim',\n",
        "            'recommendation': 'Consider increasing retire threshold to reduce overhead',\n",
        "        })\n",
        "    \n",
        "    # Check for good health\n",
        "    if not recommendations:\n",
        "        recommendations.append({\n",
        "            'severity': 'success',\n",
        "            'category': 'Overall',\n",
        "            'issue': 'SMR operating normally',\n",
        "            'recommendation': 'No optimization needed',\n",
        "        })\n",
        "    \n",
        "    return recommendations\n",
        "\n",
        "recommendations = generate_smr_recommendations(report)\n",
        "\n",
        "severity_icons = {\n",
        "    'error': '\\U0001F534',\n",
        "    'warning': '\\U0001F7E0',\n",
        "    'info': '\\U0001F7E1',\n",
        "    'success': '\\u2705',\n",
        "}\n",
        "\n",
        "print(\"### SMR Recommendations ###\\n\")\n",
        "for rec in recommendations:\n",
        "    icon = severity_icons.get(rec['severity'], '')\n",
        "    print(f\"{icon} [{rec['category']}] {rec['issue']}\")\n",
        "    print(f\"   ‚Üí {rec['recommendation']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook analyzed SMR behavior including:\n",
        "\n",
        "1. **Epoch Analysis** - Advancement rate and lag\n",
        "2. **Reclamation Metrics** - Latency, efficiency, poll statistics\n",
        "3. **Memory Pressure** - Utilization vs theoretical bounds\n",
        "4. **Stall Analysis** - Identified blocking threads\n",
        "5. **Per-Thread Stats** - Critical section times, retire/reclaim counts\n",
        "6. **Visualizations** - Charts for quick understanding\n",
        "7. **Recommendations** - Actionable optimization suggestions\n",
        "\n",
        "For comparing SMR schemes, see `memory_subsystem_comparison.ipynb`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
